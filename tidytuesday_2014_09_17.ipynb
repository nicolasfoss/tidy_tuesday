{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Tuesday Project for September 17th, 2024\n",
    "\n",
    "Hello there, folks!  I am coming at you with my first #tidytuesday project.  I am currently learning the [Julia](https://julialang.org/) programming language, and so that is what I am going to use in this notebook.\n",
    "\n",
    "Please feel free to critique me if you are a Julia programmer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Shakespeare Dialogue Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to [nrennie](https://github.com/nrennie), we have access to a dataset that you can find --> [here](https://github.com/nrennie/shakespeare).\n",
    "\n",
    "The author of the dataset we are using webscraped the data from [here](https://shakespeare.mit.edu/).\n",
    "\n",
    "Let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# import Pkg and then other required packages\n",
    "using Pkg\n",
    "Pkg.add([\"CSV\", \"DataFrames\", \"HTTP\", \"Statistics\", \"StatsPlots\", \"Plots\"])\n",
    "\n",
    "# load\n",
    "using CSV, DataFrames, HTTP, Statistics, StatsPlots, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Read directly from GitHub\n",
    "hamlet_url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/hamlet.csv\"\n",
    "macbeth_url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/macbeth.csv\"\n",
    "romeo_juliet_url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/romeo_juliet.csv\"\n",
    "\n",
    "# Create DataFrames\n",
    "hamlet = CSV.read(HTTP.get(hamlet_url).body, DataFrame)\n",
    "macbeth = CSV.read(HTTP.get(macbeth_url).body, DataFrame)\n",
    "romeo_juliet = CSV.read(HTTP.get(romeo_juliet_url).body, DataFrame);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamlet 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Description\n",
    "describe(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Number of unique characters\n",
    "unique_characters = unique(hamlet.character)\n",
    "println(\"Number of unique characters: \", length(unique_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Most frequent characters\n",
    "character_counts = combine(groupby(hamlet, :character), nrow => :Count)\n",
    "sorted_counts = sort(character_counts, :Count, rev=true)\n",
    "println(\"Most frequent characters:\\n\", sorted_counts[1:10, :character, :Count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of dialogue lengths\n",
    "hamlet.dialogue_length = length.(hamlet.dialogue)\n",
    "\n",
    "histogram(hamlet.dialogue_length, \n",
    "bins=20, \n",
    "title=\"Distribution of Dialogue Lengths in Hamlet\", \n",
    "xlabel=\"Dialogue Length\", \n",
    "ylabel=\"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Plot line number distribution by act and scene\n",
    "scatter(hamlet.line_number, \n",
    "hamlet.act, \n",
    "group=hamlet.scene, \n",
    "legend=:topright, \n",
    "title=\"Line Number Distribution by Act and Scene\", \n",
    "xlabel=\"Line Number\", \n",
    "ylabel=\"Act\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macbeth 🗡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Description\n",
    "describe(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Number of unique characters\n",
    "unique_characters_macbeth = unique(macbeth.character)\n",
    "println(\"Number of unique characters: \", length(unique_characters_macbeth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Most frequent characters\n",
    "character_counts_macbeth = combine(groupby(macbeth, :character), nrow => :Count)\n",
    "sorted_counts_macbeth = sort(character_counts_macbeth, :Count, rev=true)\n",
    "println(\"Most frequent characters:\\n\", sorted_counts_macbeth[1:10, :character, :Count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of dialogue lengths\n",
    "macbeth.dialogue_length = length.(macbeth.dialogue)\n",
    "histogram(macbeth.dialogue_length, \n",
    "bins=20, \n",
    "title=\"Distribution of Dialogue Lengths in Macbeth\", \n",
    "xlabel=\"Dialogue Length\", \n",
    "ylabel=\"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Plot line number distribution by act and scene\n",
    "scatter(macbeth.line_number, \n",
    "macbeth.act, \n",
    "group=macbeth.scene, \n",
    "legend=:topright, \n",
    "title=\"Line Number Distribution by Act and Scene\", \n",
    "xlabel=\"Line Number\", \n",
    "ylabel=\"Act\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romeo & Juliet ❤️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Description\n",
    "describe(romeo_juliet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Number of unique characters\n",
    "unique_characters_rj = unique(romeo_juliet.character)\n",
    "println(\"Number of unique characters: \", length(unique_characters_rj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Most frequent characters\n",
    "character_counts_rj = combine(groupby(romeo_juliet, :character), nrow => :Count)\n",
    "sorted_counts_rj = sort(character_counts_rj, :Count, rev=true)\n",
    "println(\"Most frequent characters:\\n\", sorted_counts_rj[1:10, :character, :Count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of dialogue lengths\n",
    "romeo_juliet.dialogue_length = length.(romeo_juliet.dialogue)\n",
    "histogram(romeo_juliet.dialogue_length, \n",
    "bins=20, \n",
    "title=\"Distribution of Dialogue Lengths in Romeo & Juliet\", \n",
    "xlabel=\"Dialogue Length\", \n",
    "ylabel=\"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Plot line number distribution by act and scene\n",
    "scatter(romeo_juliet.line_number, \n",
    "romeo_juliet.act, \n",
    "group=romeo_juliet.scene, \n",
    "legend=:topright, \n",
    "title=\"Line Number Distribution by Act and Scene\", \n",
    "xlabel=\"Line Number\", \n",
    "ylabel=\"Act\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Techniques and Suggested Methods\n",
    "- **Text Preprocessing and Tokenization**: Use `WordTokenizers.jl` for breaking down the text into tokens (words).\n",
    "- **Word Embeddings**: Use pre-trained word embeddings with `Embeddings.jl` or train your own with `Word2Vec`.\n",
    "- **Semantic Similarity**: Measure how similar different characters or dialogues are using embeddings.\n",
    "- **Topic Modeling**: Use `TextAnalysis.jl` to identify topics in the dialogues.\n",
    "- **Named Entity Recognition (NER)**: Identify names of characters, locations, etc., using `Languages.jl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using WordTokenizers\n",
    "\n",
    "# Example: Tokenize dialogues in Hamlet\n",
    "tokens_hamlet = [tokenize(lowercase(dialogue)) for dialogue in hamlet.dialogue]\n",
    "\n",
    "# Display a few tokenized dialogues\n",
    "println(\"Sample Tokenized Dialogues:\\n\", tokens_hamlet[1:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "Using Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using Embeddings\n",
    "\n",
    "# Load pre-trained GloVe embeddings (if available)\n",
    "embedding = Embeddings.load(\"path_to_pretrained_embeddings/glove.6B.100d.txt\") # Adjust path\n",
    "\n",
    "# Get embedding for a word\n",
    "word_embedding = embedding[\"king\"]  # Example word\n",
    "\n",
    "println(\"Word Embedding for 'king':\\n\", word_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using Word2Vec\n",
    "\n",
    "# Train Word2Vec model on the tokenized dialogues\n",
    "model = Word2Vec.train(tokens_hamlet, size=100, window=5, iter=5)\n",
    "\n",
    "# Find similar words to \"king\"\n",
    "similar_words = Word2Vec.similar_words(model, \"king\", 5)\n",
    "println(\"Words similar to 'king':\\n\", similar_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using Distances\n",
    "\n",
    "# Function to compute average embedding of a dialogue\n",
    "function average_embedding(dialogue, embedding)\n",
    "    words = filter(word -> haskey(embedding, word), dialogue)\n",
    "    if isempty(words)\n",
    "        return zeros(100)  # Assuming embedding size is 100\n",
    "    else\n",
    "        return mean(embedding[w] for w in words)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Compute embeddings for each character\n",
    "character_embeddings = Dict()\n",
    "for character in unique(hamlet.character)\n",
    "    dialogues = hamlet[hamlet.character .== character, :dialogue]\n",
    "    tokens = [tokenize(lowercase(d)) for d in dialogues]\n",
    "    avg_embed = mean(average_embedding(t, embedding) for t in tokens)\n",
    "    character_embeddings[character] = avg_embed\n",
    "end\n",
    "\n",
    "# Example: Compute cosine similarity between \"Hamlet\" and \"King\"\n",
    "similarity = cosine_dist(character_embeddings[\"HAMLET\"], character_embeddings[\"KING\"])\n",
    "println(\"Semantic similarity between Hamlet and King: \", similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "Latent Dirichlet Allocation (LDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using TextAnalysis\n",
    "\n",
    "# Convert dialogues to a document-term matrix\n",
    "corpus = Corpus(hamlet.dialogue)\n",
    "tf = TermDocumentMatrix(corpus)\n",
    "\n",
    "# Fit LDA model with 5 topics\n",
    "lda_model = LDA(tf, 5)\n",
    "\n",
    "# Display the top words for each topic\n",
    "println(\"Top words for each topic:\\n\")\n",
    "for topic in 1:5\n",
    "    println(\"Topic $topic: \", topwords(lda_model, topic))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "Identifying Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using Languages\n",
    "\n",
    "# Define a simple function to extract entities from text\n",
    "function extract_entities(text)\n",
    "    tags = tag(text)\n",
    "    return filter(t -> t.label in [\"PER\", \"LOC\", \"ORG\"], tags)\n",
    "end\n",
    "\n",
    "# Extract entities from sample dialogues\n",
    "entities = [extract_entities(d) for d in hamlet.dialogue[1:5]]\n",
    "println(\"Entities in sample dialogues:\\n\", entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Techniques\n",
    "- **Text Preprocessing and Tokenization**: Prepares the data for analysis.\n",
    "- **Word Embeddings**: Encodes words into numerical vectors, capturing semantic meaning.\n",
    "- **Semantic Similarity**: Quantifies similarity between characters' dialogues.\n",
    "- **Topic Modeling**: Finds latent topics in dialogues, useful for discovering themes.\n",
    "- **Named Entity Recognition**: Identifies important names, places, and organizations.\n",
    "\n",
    "These techniques enable a deeper understanding of the text, exploring character relationships, thematic elements, and more subtle textual patterns. The choice of method depends on the specific questions you want to answer using this dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
